{
  "nbformat_minor": 1, 
  "nbformat": 4, 
  "cells": [
    {
      "source": [
        "from numpy import array\n", 
        "from keras.preprocessing.text import Tokenizer\n", 
        "from keras.utils import to_categorical\n", 
        "from keras.preprocessing.sequence import pad_sequences\n", 
        "from keras.utils.vis_utils import plot_model\n", 
        "from keras.models import Sequential\n", 
        "from keras.layers import Dense\n", 
        "from keras.layers import LSTM\n", 
        "from keras.layers import Embedding\n", 
        "from PIL import Image\n", 
        "from IPython.display import display # to display images\n", 
        "import tensorflow.python.util.deprecation as deprecation\n", 
        "deprecation._PRINT_DEPRECATION_WARNINGS = False\n", 
        "\n", 
        "# generate a sequence from a language model\n", 
        "def generate_seq(model, tokenizer, max_length, seed_text, n_words):\n", 
        "\tin_text = seed_text\n", 
        "\t# generate a fixed number of words\n", 
        "\tfor _ in range(n_words):\n", 
        "\t\t# encode the text as integer\n", 
        "\t\tencoded = tokenizer.texts_to_sequences([in_text])[0]\n", 
        "\t\t# pre-pad sequences to a fixed length\n", 
        "\t\tencoded = pad_sequences([encoded], maxlen=max_length, padding='pre')\n", 
        "\t\t# predict probabilities for each word\n", 
        "\t\tyhat = model.predict_classes(encoded, verbose=0)\n", 
        "\t\t# map predicted word index to word\n", 
        "\t\tout_word = ''\n", 
        "\t\tfor word, index in tokenizer.word_index.items():\n", 
        "\t\t\tif index == yhat:\n", 
        "\t\t\t\tout_word = word\n", 
        "\t\t\t\tbreak\n", 
        "\t\t# append to input\n", 
        "\t\tin_text += ' ' + out_word\n", 
        "\treturn in_text\n", 
        "\n", 
        "# define the model\n", 
        "def define_model(vocab_size, max_length):\n", 
        "\tmodel = Sequential()\n", 
        "\tmodel.add(Embedding(vocab_size, 10, input_length=max_length-1))\n", 
        "\tmodel.add(LSTM(50))\n", 
        "\tmodel.add(Dense(vocab_size, activation='softmax'))\n", 
        "\t# compile network\n", 
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n", 
        "\t# summarize defined model\n", 
        "\tmodel.summary()\n", 
        "\tplot_model(model, to_file='model.png', show_shapes=True)\n", 
        "\timage = Image.open('model.png')\n", 
        "\tdisplay(image)\n", 
        "\treturn model\n", 
        "\n", 
        "# source text\n", 
        "data = \"\"\" Jack and Jill went up the hill\\n\n", 
        "\t\tTo fetch a pail of water\\n\n", 
        "\t\tJack fell down and broke his crown\\n\n", 
        "\t\tAnd Jill came tumbling after\\n \"\"\"\n", 
        "# prepare the tokenizer on the source text\n", 
        "tokenizer = Tokenizer()\n", 
        "tokenizer.fit_on_texts([data])\n", 
        "# determine the vocabulary size\n", 
        "vocab_size = len(tokenizer.word_index) + 1\n", 
        "print('Vocabulary Size: %d' % vocab_size)\n", 
        "# create line-based sequences\n", 
        "sequences = list()\n", 
        "for line in data.split('\\n'):\n", 
        "\tencoded = tokenizer.texts_to_sequences([line])[0]\n", 
        "\tfor i in range(1, len(encoded)):\n", 
        "\t\tsequence = encoded[:i+1]\n", 
        "\t\tsequences.append(sequence)\n", 
        "print('Total Sequences: %d' % len(sequences))\n", 
        "# pad input sequences\n", 
        "max_length = max([len(seq) for seq in sequences])\n", 
        "sequences = pad_sequences(sequences, maxlen=max_length, padding='pre')\n", 
        "print('Max Sequence Length: %d' % max_length)\n", 
        "# split into input and output elements\n", 
        "sequences = array(sequences)\n", 
        "X, y = sequences[:,:-1],sequences[:,-1]\n", 
        "y = to_categorical(y, num_classes=vocab_size)\n", 
        "# define model\n", 
        "model = define_model(vocab_size, max_length)\n", 
        "# fit network\n", 
        "model.fit(X, y, epochs=250, verbose=2)\n", 
        "# evaluate model\n", 
        "print(generate_seq(model, tokenizer, max_length-1, 'Jack', 4))\n", 
        "print(generate_seq(model, tokenizer, max_length-1, 'Jill', 4))\n"
      ], 
      "cell_type": "code", 
      "execution_count": null, 
      "outputs": [], 
      "metadata": {}
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3", 
      "name": "python3", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "3.6.1", 
      "pygments_lexer": "ipython3", 
      "codemirror_mode": {
        "version": 3, 
        "name": "ipython"
      }
    }, 
    "anaconda-cloud": {}
  }
}