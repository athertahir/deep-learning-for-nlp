{
  "nbformat_minor": 1, 
  "nbformat": 4, 
  "cells": [
    {
      "source": [
        "from numpy import array\n", 
        "from pickle import dump\n", 
        "from keras.utils import to_categorical\n", 
        "from keras.utils.vis_utils import plot_model\n", 
        "from keras.models import Sequential\n", 
        "from keras.layers import Dense\n", 
        "from keras.layers import LSTM\n", 
        "from PIL import Image\n", 
        "from IPython.display import display # to display images\n", 
        "\n", 
        "# load doc into memory\n", 
        "def load_doc(filename):\n", 
        "\t# open the file as read only\n", 
        "\tfile = open(filename, 'r')\n", 
        "\t# read all text\n", 
        "\ttext = file.read()\n", 
        "\t# close the file\n", 
        "\tfile.close()\n", 
        "\treturn text\n", 
        "\n", 
        "# define the model\n", 
        "def define_model(X):\n", 
        "\tmodel = Sequential()\n", 
        "\tmodel.add(LSTM(75, input_shape=(X.shape[1], X.shape[2])))\n", 
        "\tmodel.add(Dense(vocab_size, activation='softmax'))\n", 
        "\t# compile model\n", 
        "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n", 
        "\t# summarize defined model\n", 
        "\tmodel.summary()\n", 
        "\tplot_model(model, to_file='model.png', show_shapes=True)\n", 
        "\timage = Image.open('model.png')\n", 
        "\tdisplay(image)\n", 
        "\treturn model\n", 
        "\n", 
        "# load\n", 
        "in_filename = 'char_sequences.txt'\n", 
        "raw_text = load_doc(in_filename)\n", 
        "lines = raw_text.split('\\n')\n", 
        "# integer encode sequences of characters\n", 
        "chars = sorted(list(set(raw_text)))\n", 
        "mapping = dict((c, i) for i, c in enumerate(chars))\n", 
        "sequences = list()\n", 
        "for line in lines:\n", 
        "\t# integer encode line\n", 
        "\tencoded_seq = [mapping[char] for char in line]\n", 
        "\t# store\n", 
        "\tsequences.append(encoded_seq)\n", 
        "# vocabulary size\n", 
        "vocab_size = len(mapping)\n", 
        "print('Vocabulary Size: %d' % vocab_size)\n", 
        "# separate into input and output\n", 
        "sequences = array(sequences)\n", 
        "X, y = sequences[:,:-1], sequences[:,-1]\n", 
        "sequences = [to_categorical(x, num_classes=vocab_size) for x in X]\n", 
        "X = array(sequences)\n", 
        "y = to_categorical(y, num_classes=vocab_size)\n", 
        "# define model\n", 
        "model = define_model(X)\n", 
        "# fit model\n", 
        "model.fit(X, y, epochs=100, verbose=2)\n", 
        "# save the model to file\n", 
        "model.save('model.h5')\n", 
        "# save the mapping\n", 
        "dump(mapping, open('mapping.pkl', 'wb'))"
      ], 
      "cell_type": "code", 
      "execution_count": null, 
      "outputs": [], 
      "metadata": {}
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3", 
      "name": "python3", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "3.6.1", 
      "pygments_lexer": "ipython3", 
      "codemirror_mode": {
        "version": 3, 
        "name": "ipython"
      }
    }, 
    "anaconda-cloud": {}
  }
}