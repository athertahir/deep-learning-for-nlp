{
  "nbformat_minor": 1, 
  "nbformat": 4, 
  "cells": [
    {
      "source": [
        "from pickle import load\n", 
        "\n", 
        "# load doc into memory\n", 
        "def load_doc(filename):\n", 
        "\t# open the file as read only\n", 
        "\tfile = open(filename, 'r')\n", 
        "\t# read all text\n", 
        "\ttext = file.read()\n", 
        "\t# close the file\n", 
        "\tfile.close()\n", 
        "\treturn text\n", 
        "\n", 
        "# load a pre-defined list of photo identifiers\n", 
        "def load_set(filename):\n", 
        "\tdoc = load_doc(filename)\n", 
        "\tdataset = list()\n", 
        "\t# process line by line\n", 
        "\tfor line in doc.split('\\n'):\n", 
        "\t\t# skip empty lines\n", 
        "\t\tif len(line) < 1:\n", 
        "\t\t\tcontinue\n", 
        "\t\t# get the image identifier\n", 
        "\t\tidentifier = line.split('.')[0]\n", 
        "\t\tdataset.append(identifier)\n", 
        "\treturn set(dataset)\n", 
        "\n", 
        "# load clean descriptions into memory\n", 
        "def load_clean_descriptions(filename, dataset):\n", 
        "\t# load document\n", 
        "\tdoc = load_doc(filename)\n", 
        "\tdescriptions = dict()\n", 
        "\tfor line in doc.split('\\n'):\n", 
        "\t\t# split line by white space\n", 
        "\t\ttokens = line.split()\n", 
        "\t\t# split id from description\n", 
        "\t\timage_id, image_desc = tokens[0], tokens[1:]\n", 
        "\t\t# skip images not in the set\n", 
        "\t\tif image_id in dataset:\n", 
        "\t\t\t# create list\n", 
        "\t\t\tif image_id not in descriptions:\n", 
        "\t\t\t\tdescriptions[image_id] = list()\n", 
        "\t\t\t# wrap description in tokens\n", 
        "\t\t\tdesc = 'startseq ' + ' '.join(image_desc) + ' endseq'\n", 
        "\t\t\t# store\n", 
        "\t\t\tdescriptions[image_id].append(desc)\n", 
        "\treturn descriptions\n", 
        "\n", 
        "# load photo features\n", 
        "def load_photo_features(filename, dataset):\n", 
        "\t# load all features\n", 
        "\tall_features = load(open(filename, 'rb'))\n", 
        "\t# filter features\n", 
        "\tfeatures = {k: all_features[k] for k in dataset}\n", 
        "\treturn features\n", 
        "\n", 
        "# load training dataset (6K)\n", 
        "filename = 'Flickr8k_text/Flickr_8k.trainImages.txt'\n", 
        "train = load_set(filename)\n", 
        "print('Dataset: %d' % len(train))\n", 
        "# descriptions\n", 
        "train_descriptions = load_clean_descriptions('descriptions.txt', train)\n", 
        "print('Descriptions: train=%d' % len(train_descriptions))\n", 
        "# photo features\n", 
        "train_features = load_photo_features('features.pkl', train)\n", 
        "print('Photos: train=%d' % len(train_features))"
      ], 
      "cell_type": "code", 
      "execution_count": null, 
      "outputs": [], 
      "metadata": {}
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3", 
      "name": "python3", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "3.6.1", 
      "pygments_lexer": "ipython3", 
      "codemirror_mode": {
        "version": 3, 
        "name": "ipython"
      }
    }, 
    "anaconda-cloud": {}
  }
}