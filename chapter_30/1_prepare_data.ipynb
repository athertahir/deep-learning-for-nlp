{
  "nbformat_minor": 1, 
  "nbformat": 4, 
  "cells": [
    {
      "source": [
        "import string\n", 
        "import re\n", 
        "from pickle import dump\n", 
        "from unicodedata import normalize\n", 
        "from numpy import array\n", 
        "\n", 
        "# load doc into memory\n", 
        "def load_doc(filename):\n", 
        "\t# open the file as read only\n", 
        "\tfile = open(filename, mode='rt', encoding='utf-8')\n", 
        "\t# read all text\n", 
        "\ttext = file.read()\n", 
        "\t# close the file\n", 
        "\tfile.close()\n", 
        "\treturn text\n", 
        "\n", 
        "# split a loaded document into sentences\n", 
        "def to_pairs(doc):\n", 
        "\tlines = doc.strip().split('\\n')\n", 
        "\tpairs = [line.split('\\t') for line in  lines]\n", 
        "\treturn pairs\n", 
        "\n", 
        "# clean a list of lines\n", 
        "def clean_pairs(lines):\n", 
        "\tcleaned = list()\n", 
        "\t# prepare regex for char filtering\n", 
        "\tre_punc = re.compile('[%s]' % re.escape(string.punctuation))\n", 
        "\tre_print = re.compile('[^%s]' % re.escape(string.printable))\n", 
        "\tfor pair in lines:\n", 
        "\t\tclean_pair = list()\n", 
        "\t\tfor line in pair:\n", 
        "\t\t\t# normalize unicode characters\n", 
        "\t\t\tline = normalize('NFD', line).encode('ascii', 'ignore')\n", 
        "\t\t\tline = line.decode('UTF-8')\n", 
        "\t\t\t# tokenize on white space\n", 
        "\t\t\tline = line.split()\n", 
        "\t\t\t# convert to lowercase\n", 
        "\t\t\tline = [word.lower() for word in line]\n", 
        "\t\t\t# remove punctuation from each token\n", 
        "\t\t\tline = [re_punc.sub('', w) for w in line]\n", 
        "\t\t\t# remove non-printable chars form each token\n", 
        "\t\t\tline = [re_print.sub('', w) for w in line]\n", 
        "\t\t\t# remove tokens with numbers in them\n", 
        "\t\t\tline = [word for word in line if word.isalpha()]\n", 
        "\t\t\t# store as string\n", 
        "\t\t\tclean_pair.append(' '.join(line))\n", 
        "\t\tcleaned.append(clean_pair)\n", 
        "\treturn array(cleaned)\n", 
        "\n", 
        "# save a list of clean sentences to file\n", 
        "def save_clean_data(sentences, filename):\n", 
        "\tdump(sentences, open(filename, 'wb'))\n", 
        "\tprint('Saved: %s' % filename)\n", 
        "\n", 
        "# load dataset\n", 
        "filename = 'deu.txt'\n", 
        "doc = load_doc(filename)\n", 
        "# split into english-german pairs\n", 
        "pairs = to_pairs(doc)\n", 
        "# clean sentences\n", 
        "clean_pairs = clean_pairs(pairs)\n", 
        "# save clean pairs to file\n", 
        "save_clean_data(clean_pairs, 'english-german.pkl')\n", 
        "# spot check\n", 
        "for i in range(100):\n", 
        "\tprint('[%s] => [%s]' % (clean_pairs[i,0], clean_pairs[i,1]))"
      ], 
      "cell_type": "code", 
      "execution_count": null, 
      "outputs": [], 
      "metadata": {}
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3", 
      "name": "python3", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "3.6.1", 
      "pygments_lexer": "ipython3", 
      "codemirror_mode": {
        "version": 3, 
        "name": "ipython"
      }
    }, 
    "anaconda-cloud": {}
  }
}